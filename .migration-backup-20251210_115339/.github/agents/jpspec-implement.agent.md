---
name: "jpspec-implement"
description: "Execute implementation using specialized frontend and backend engineer agents with code review."
target: "chat"
tools:
  - "Read"
  - "Write"
  - "Edit"
  - "Grep"
  - "Glob"
  - "Bash"
  - "mcp__backlog__*"
  - "mcp__serena__*"
  - "Skill"

handoffs:
  - label: "Run Validation"
    agent: "jpspec-validate"
    prompt: "Implementation is complete. Run QA validation, security review, and documentation checks."
    send: false
---
## User Input

```text
$ARGUMENTS
```

You **MUST** consider the user input before proceeding (if not empty).

## Execution Instructions

This command implements features using specialized engineering agents with integrated code review. **Engineers work exclusively from backlog tasks.**

# Constitution Pre-flight Check

**CRITICAL**: This command requires constitution validation before execution (unless `--skip-validation` is provided).

## Step 0.5: Check Constitution Status

Before executing this workflow command, validate the project's constitution:

### 1. Check Constitution Exists

```bash
# Look for constitution file
if [ -f "memory/constitution.md" ]; then
  echo "‚úì Constitution found"
else
  echo "‚ö†Ô∏è No constitution found"
  echo ""
  echo "To create one:"
  echo "  1. Run: specify init --here"
  echo "  2. Then: Run /speckit:constitution to customize"
  echo ""
  echo "Proceeding without constitution..."
fi
```

If no constitution exists:
- Warn the user
- Suggest creating one with `specify init --here`
- Continue with command (constitution is recommended but not required)

### 2. If Constitution Exists, Check Validation Status

```bash
# Detect tier from TIER comment (default: Medium if not found)
TIER=$(grep -o "TIER: \(Light\|Medium\|Heavy\)" memory/constitution.md | cut -d' ' -f2)
TIER=${TIER:-Medium}  # Default to Medium if not found

# Count NEEDS_VALIDATION markers
MARKER_COUNT=$(grep -c "NEEDS_VALIDATION" memory/constitution.md || echo 0)

# Extract section names from NEEDS_VALIDATION markers
SECTIONS=$(grep "NEEDS_VALIDATION" memory/constitution.md | sed 's/.*NEEDS_VALIDATION: /  - /')

echo "Constitution tier: $TIER"
echo "Unvalidated sections: $MARKER_COUNT"
```

### 3. Apply Tier-Based Enforcement

#### Light Tier - Warn Only

If `TIER = Light` and `MARKER_COUNT > 0`:

```text
‚ö†Ô∏è Constitution has N unvalidated sections:
$SECTIONS

Consider running /speckit:constitution to customize your constitution.

Proceeding with command...
```

Then continue with the command.

#### Medium Tier - Warn and Confirm

If `TIER = Medium` and `MARKER_COUNT > 0`:

```text
‚ö†Ô∏è Constitution Validation Recommended

Your constitution has N unvalidated sections:
$SECTIONS

Medium tier projects should validate their constitution before workflow commands.

Options:
  1. Continue anyway (y/N)
  2. Run /speckit:constitution to customize
  3. Run specify constitution validate to check status

Continue without validation? [y/N]: _
```

Wait for user response:
- If user responds `y` or `yes` ‚Üí Continue with command
- If user responds `n`, `no`, or empty/Enter ‚Üí Stop and show:
  ```text
  Command cancelled. Run /speckit:constitution to customize your constitution.
  ```

#### Heavy Tier - Block Until Validated

If `TIER = Heavy` and `MARKER_COUNT > 0`:

```text
‚ùå Constitution Validation Required

Your constitution has N unvalidated sections:
$SECTIONS

Heavy tier constitutions require full validation before workflow commands.

To resolve:
  1. Run /speckit:constitution to customize your constitution
  2. Run specify constitution validate to verify
  3. Remove all NEEDS_VALIDATION markers

Or use --skip-validation to bypass (not recommended).

Command blocked until constitution is validated.
```

**DO NOT PROCEED** with the command. Exit and wait for user to resolve.

### 4. Skip Validation Flag

If the command was invoked with `--skip-validation`:

```bash
# Check for skip flag in arguments
if [[ "$ARGUMENTS" == *"--skip-validation"* ]]; then
  echo "‚ö†Ô∏è Skipping constitution validation (--skip-validation)"
  # Remove the flag from arguments and continue
  ARGUMENTS="${ARGUMENTS/--skip-validation/}"
fi
```

When skip flag is present:
- Log warning
- Skip all validation checks
- Continue with command
- Note: For emergency use only

### 5. Fully Validated Constitution

If `MARKER_COUNT = 0`:

```text
‚úì Constitution validated
```

Continue with command normally.

## Summary: When to Block vs Warn

| Tier | Unvalidated Sections | Action |
|------|---------------------|--------|
| Light | 0 | ‚úì Continue |
| Light | >0 | ‚ö†Ô∏è Warn, continue |
| Medium | 0 | ‚úì Continue |
| Medium | >0 | ‚ö†Ô∏è Warn, ask confirmation, respect user choice |
| Heavy | 0 | ‚úì Continue |
| Heavy | >0 | ‚ùå Block, require validation |
| Any | >0 + `--skip-validation` | ‚ö†Ô∏è Warn, continue |

## Integration Example

```markdown
---
description: Your command description
---

## User Input

```text
$ARGUMENTS
```

You **MUST** consider the user input before proceeding (if not empty).

{{INCLUDE:.claude/commands/jpspec/_constitution-check.md}}

{{INCLUDE:.claude/commands/jpspec/_workflow-state.md}}

## Execution Instructions

[Rest of your command implementation...]
```

## Related Commands

| Command | Purpose |
|---------|---------|
| `specify init --here` | Initialize constitution if missing |
| `/speckit:constitution` | Interactive constitution customization |
| `specify constitution validate` | Check validation status and show report |
| `specify constitution show` | Display current constitution |


# Workflow State Validation

## Step 0: Workflow State Validation (REQUIRED)

**CRITICAL**: This command requires a task to be in the correct workflow state before execution.

### Light Mode Detection

First, check if this project is in light mode:

```bash
# Check for light mode marker
if [ -f ".jpspec-light-mode" ]; then
  echo "Project is in LIGHT MODE (~60% faster workflow)"
fi
```

**Light Mode Behavior**:
- `/jpspec:research` ‚Üí **SKIPPED** (inform user and suggest `/jpspec:plan` instead)
- `/jpspec:plan` ‚Üí Uses `plan-light.md` template (high-level only)
- `/jpspec:specify` ‚Üí Uses `spec-light.md` template (combined stories + AC)

If in light mode and the current command is `/jpspec:research`, inform the user:
```text
‚ÑπÔ∏è This project is in Light Mode

Light mode skips the research phase for faster iteration.
Current state: workflow:Specified

Suggestions:
  - Run /jpspec:plan to proceed directly to planning
  - To enable research, delete .jpspec-light-mode and use full mode
  - See docs/guides/when-to-use-light-mode.md for details
```

### 1. Get Current Task and State

```bash
# Find the task you're working on
# Option A: If task ID was provided in arguments, use that
# Option B: Look for task currently "In Progress"
backlog task list -s "In Progress" --plain

# Get task details and extract workflow state from labels
TASK_ID="<task-id>"  # Replace with actual task ID
backlog task "$TASK_ID" --plain
```

### 2. Check Workflow State

Extract the `workflow:*` label from the task. The state must match one of the **Required Input States** for this command:

| Command | Required Input States | Output State |
|---------|----------------------|--------------|
| /jpspec:assess | workflow:To Do, (no workflow label) | workflow:Assessed |
| /jpspec:specify | workflow:Assessed | workflow:Specified |
| /jpspec:research | workflow:Specified | workflow:Researched |
| /jpspec:plan | workflow:Specified, workflow:Researched | workflow:Planned |
| /jpspec:implement | workflow:Planned | workflow:In Implementation |
| /jpspec:validate | workflow:In Implementation | workflow:Validated |
| /jpspec:operate | workflow:Validated | workflow:Deployed |

### 3. Handle Invalid State

If the task's workflow state doesn't match the required input states:

```text
‚ö†Ô∏è Cannot run /jpspec:<command>

Current state: "<current-workflow-label>"
Required states: <list-of-valid-input-states>

Suggestions:
  - Valid workflows for current state: <list-valid-commands>
  - Use --skip-state-check to bypass (not recommended)
```

**DO NOT PROCEED** unless:
- The task is in a valid input state, OR
- User explicitly requests to skip the check

### 4. Update State After Completion

After successful workflow completion, update the task's workflow state:

```bash
# Remove old workflow label and add new one
# Replace <output-state> with the output state from the table above
backlog task edit "$TASK_ID" -l "workflow:<output-state>"
```

## Workflow State Labels Reference

Tasks use labels with the `workflow:` prefix to track their current workflow state:

- `workflow:Assessed` - SDD suitability evaluated (/jpspec:assess complete)
- `workflow:Specified` - Requirements captured (/jpspec:specify complete)
- `workflow:Researched` - Technical research completed (/jpspec:research complete)
- `workflow:Planned` - Architecture planned (/jpspec:plan complete)
- `workflow:In Implementation` - Code being written (/jpspec:implement in progress)
- `workflow:Validated` - QA and security validated (/jpspec:validate complete)
- `workflow:Deployed` - Released to production (/jpspec:operate complete)

## Programmatic State Checking

The state guard module can also be used programmatically:

```python
from specify_cli.workflow import check_workflow_state, get_valid_workflows

# Check if current state allows command execution
can_proceed, message = check_workflow_state("implement", current_state)

if not can_proceed:
    print(message)
    # Shows error with suggestions

# Get valid commands for a state
valid_commands = get_valid_workflows("Specified")
# Returns: ['/jpspec:research', '/jpspec:plan']
```

## Bypassing State Checks (Power Users Only)

State checks can be bypassed in special circumstances:
- Emergency hotfixes
- Iterative refinement of specifications
- Recovery from failed workflows

Use `--skip-state-check` flag or explicitly acknowledge the bypass.

**Warning**: Bypassing state checks may result in incomplete artifacts or broken workflows.


**For /jpspec:implement**: Required input state is `workflow:Planned`. Output state will be `workflow:In Implementation`.

If the task doesn't have the required workflow state, inform the user:
- If task needs planning first: suggest running `/jpspec:plan`
- If task needs specification: suggest running `/jpspec:specify` first

**Proceed to Step 1 ONLY if workflow validation passes.**

### Step 1: Discover Backlog Tasks

**‚ö†Ô∏è CRITICAL: This command REQUIRES existing backlog tasks to work on.**

Discover tasks for implementation:

```bash
# Search for implementation tasks related to this feature
backlog search "$ARGUMENTS" --plain

# List available tasks to work on
backlog task list -s "To Do" --plain

# List any in-progress tasks for context
backlog task list -s "In Progress" --plain
```

**If no relevant tasks are found:**

```
‚ö†Ô∏è No backlog tasks found for: [FEATURE NAME]

This command requires existing backlog tasks with defined acceptance criteria.
Please run /jpspec:specify first to create implementation tasks, or create
tasks manually using:

  backlog task create "Implement [Feature]" --ac "Criterion 1" --ac "Criterion 2"

Then re-run /jpspec:implement
```

**If tasks ARE found, proceed to Step 2.**

### Step 2: Discover Related Specifications and ADRs

**‚ö†Ô∏è CRITICAL: Implementation MUST be informed by all relevant design documents.**

Before coding, discover ALL related PRDs, Functional Specs, Technical Specs, and ADRs:

```bash
# Search for PRDs related to this feature
ls -la docs/prd/ 2>/dev/null || echo "No PRDs found"
grep -rl "$ARGUMENTS" docs/prd/ 2>/dev/null || echo "No matching PRDs"

# Search for Functional and Technical Specs
ls -la docs/specs/ 2>/dev/null || echo "No specs found"
grep -rl "$ARGUMENTS" docs/specs/ 2>/dev/null || echo "No matching specs"

# Search for related ADRs (architecture decisions)
ls -la docs/adr/ 2>/dev/null || echo "No ADRs found"
grep -rl "$ARGUMENTS" docs/adr/ 2>/dev/null || echo "No matching ADRs"

# Search backlog task descriptions for spec/ADR references
backlog task list --plain 2>/dev/null | grep -i "prd\|spec\|adr"
```

**Read ALL discovered documents before implementation:**

The artifact progression is:
```
PRD ‚Üí Functional Spec ‚Üí Technical Spec ‚Üí ADR ‚Üí Implementation
```

| Document | What It Tells You |
|----------|-------------------|
| **PRD** | What the product must do and why the user cares |
| **Functional Spec** | What behaviors and capabilities are required |
| **Technical Spec** | How to build it (architecture, data, APIs) |
| **ADR** | Why we chose this technical path |

**If key documents are missing:**

```
‚ö†Ô∏è Missing design documents for: [FEATURE NAME]

Found:
- PRD: [‚úì/‚úó]
- Functional Spec: [‚úì/‚úó]
- Technical Spec: [‚úì/‚úó]
- ADRs: [‚úì/‚úó]

Recommendation:
- Run /jpspec:specify to create PRD and Functional Spec
- Run /jpspec:plan to create Technical Spec and ADRs
- Then re-run /jpspec:implement

Proceeding without specs may result in:
- Misaligned implementation
- Undefined edge cases
- Inconsistent architecture
- Undocumented decisions
```

**If documents ARE found, read them and proceed to Phase 0.**

### Checkpoint Reminder

> **üí° Safety Tip**: Claude creates checkpoints before each code change. If implementation doesn't work as expected, you can press `Esc Esc` to instantly undo changes, or use `/rewind` for interactive rollback. This is especially useful for:
> - Multi-file refactoring
> - Experimental approaches
> - Complex migrations

### Phase 0: Quality Gate (MANDATORY)

**‚ö†Ô∏è CRITICAL: Spec quality must pass before implementation begins.**

Before starting implementation, you MUST run the quality gate:

```bash
# Run quality gate on spec.md
specify gate

# Alternative: Override threshold if needed
specify gate --threshold 60

# Emergency bypass (NOT RECOMMENDED - use only with explicit user approval)
specify gate --force
```

**Quality Gate Exit Codes:**
- `0` = PASSED - Proceed to Phase 1
- `1` = FAILED - Spec quality below threshold
- `2` = ERROR - Missing spec.md or validation error

**If gate PASSES (exit code 0):**
```
‚úÖ Quality gate passed
Proceeding with implementation...
```

**If gate FAILS (exit code 1):**
```
‚ùå Quality gate failed: Spec quality is X/100 (minimum: 70)

Recommendations:
  ‚Ä¢ Add missing section: ## Description
  ‚Ä¢ Add missing section: ## User Story
  ‚Ä¢ Reduce vague terms (currently: Y instances)
  ‚Ä¢ Add measurable acceptance criteria

Action Required:
1. Improve spec quality using recommendations
2. Re-run: specify quality .specify/spec.md
3. When quality ‚â•70, re-run: /jpspec:implement

OR (not recommended without user approval):
  specify gate --force
```

**--force Bypass:**
- Only use with explicit user approval
- Warns that bypassing quality checks may lead to unclear requirements
- Logs the bypass decision

**Proceed to Phase 1 ONLY if quality gate passes or user explicitly approves --force bypass.**

### Phase 1: Implementation (Parallel Execution)

**IMPORTANT**: Launch applicable engineer agents in parallel for maximum efficiency.

#### Frontend Implementation (if UI/mobile components needed)

Use the Task tool to launch a **general-purpose** agent (Frontend Engineer context):

```
# AGENT CONTEXT: Senior Frontend Engineer

You are a Senior Frontend Engineer with deep expertise in React, React Native, modern web standards, and mobile development. You build user interfaces that are performant, accessible, maintainable, and delightful to use.

## Core Expertise
- **Modern React Development**: React 18+ with hooks, concurrent features, server components
- **Mobile Excellence**: React Native for native-quality mobile apps
- **Performance Optimization**: Fast load times, smooth interactions, efficient rendering
- **Accessibility First**: WCAG 2.1 AA compliance, inclusive interfaces
- **Type Safety**: TypeScript for error prevention and code quality

## Key Technologies
- **State Management**: Zustand, Jotai, TanStack Query, Context API
- **Styling**: Tailwind CSS, CSS Modules, Styled Components
- **Performance**: Code splitting, memoization, virtualization, Suspense
- **Testing**: Vitest, React Testing Library, Playwright

# TASK: Implement the frontend for: [USER INPUT FEATURE]

Context:
[Include architecture, PRD, design specs, API contracts]
[Include backlog task IDs discovered in Step 0]

## Backlog Task Management (REQUIRED)

**Your Agent Identity**: @frontend-engineer

Before coding, you MUST:
1. **Pick a task**: `backlog task <task-id> --plain` to review details
2. **Assign yourself**: `backlog task edit <task-id> -s "In Progress" -a @frontend-engineer`
3. **Add implementation plan**: `backlog task edit <task-id> --plan $'1. Step 1\n2. Step 2'`

During implementation:
- **Check ACs as you complete them**: `backlog task edit <task-id> --check-ac 1`
- **Check multiple ACs**: `backlog task edit <task-id> --check-ac 1 --check-ac 2`

After implementation:
- **Add implementation notes**: `backlog task edit <task-id> --notes $'Implemented X with Y pattern\n\nKey changes:\n- File A modified\n- File B created'`
- **Verify all ACs checked**: `backlog task <task-id> --plain` (all should show `[x]`)

Implementation Requirements:

1. **Component Development**
   - Build React/React Native components
   - Implement proper TypeScript types
   - Follow component composition patterns
   - Ensure accessibility (WCAG 2.1 AA)

2. **State Management**
   - Choose appropriate state solution (local, Context, Zustand, TanStack Query)
   - Implement efficient data fetching
   - Handle loading and error states

3. **Styling and Responsiveness**
   - Implement responsive design
   - Use design system/tokens
   - Ensure cross-browser/platform compatibility

4. **Performance Optimization**
   - Code splitting and lazy loading
   - Proper memoization
   - Optimized rendering

5. **Testing**
   - Unit tests for components
   - Integration tests for user flows
   - Accessibility tests

Deliver production-ready frontend code with tests.
```

#### Backend Implementation (if API/services needed)

Use the Task tool to launch a **general-purpose** agent (Backend Engineer context):

```
# AGENT CONTEXT: Senior Backend Engineer

You are a Senior Backend Engineer with deep expertise in Go, TypeScript (Node.js), and Python. You build scalable, reliable, and maintainable backend systems including CLI tools, RESTful APIs, GraphQL services, and middleware.

## Core Expertise
- **API Development**: RESTful, GraphQL, gRPC services
- **CLI Tools**: Command-line interfaces and developer tools
- **Database Design**: Efficient data modeling and query optimization
- **System Architecture**: Scalable, resilient distributed systems
- **Performance**: High-throughput, low-latency services

## Language-Specific Expertise
- **Go**: Concurrency with goroutines, error handling, standard library
- **TypeScript/Node.js**: Async/await, event loop, modern ESM modules
- **Python**: Type hints, asyncio, modern dependency management

## Key Technologies
- **Go**: net/http, Gin, cobra (CLI), pgx (database)
- **TypeScript**: Express, Fastify, Prisma, Zod validation
- **Python**: FastAPI, SQLAlchemy, Pydantic, Click/Typer (CLI)

## Code Hygiene Requirements (MANDATORY)

Before completing ANY implementation, you MUST:

1. **Remove Unused Imports**
   - Run language-specific linter to detect unused imports
   - Delete ALL unused imports before completion
   - This is a blocking requirement - do not proceed with unused imports

2. **Language-Specific Linting**
   - **Python**: Run `ruff check --select F401,F841` (unused imports/variables)
   - **Go**: Run `go vet ./...` and check for unused imports
   - **TypeScript**: Run `tsc --noEmit` and check eslint rules

## Defensive Coding Requirements (MANDATORY)

1. **Input Validation at Boundaries**
   - Validate ALL function inputs at API/service boundaries
   - Never trust external data (API responses, file contents, env vars, user input)
   - Fail fast with clear error messages on invalid input

2. **Type Safety**
   - Use type hints/annotations on ALL public functions
   - Handle None/null/undefined explicitly - never assume values exist
   - Use union types for optional values, not implicit None

3. **Error Handling**
   - Handle all error cases explicitly
   - Provide meaningful error messages with context
   - Log errors with sufficient detail for debugging

## Language-Specific Rules

### Python (CRITICAL - Enforce Strictly)
- **Imports**: Run `ruff check --select F401` before completion
- **Types**: Type hints required on all public functions and methods
- **Validation**: Use Pydantic models or dataclasses for data validation
- **None Handling**: Use `Optional[T]` and explicit None checks
- **Example validation**:
  ```python
  from typing import Any, Dict

  def process_user(user_id: int, data: Dict[str, Any]) -> User:
      if not isinstance(user_id, int) or user_id <= 0:
          raise ValueError(f"Invalid user_id: {user_id}")
      if not data:
          raise ValueError("Data cannot be empty")
      # ... implementation
  ```

### Go
- **Imports**: Compiler enforces no unused imports (will not compile)
- **Errors**: Check ALL errors - never use `_` to ignore errors
- **Validation**: Validate struct fields, use constructor functions
- **Example validation**:
  ```go
  func NewUser(id int, name string) (*User, error) {
      if id <= 0 {
          return nil, fmt.Errorf("invalid id: %d", id)
      }
      if strings.TrimSpace(name) == "" {
          return nil, errors.New("name cannot be empty")
      }
      return &User{ID: id, Name: name}, nil
  }
  ```

### TypeScript
- **Imports**: Enable `noUnusedLocals` in tsconfig.json
- **Types**: Use strict mode, avoid `any` type
- **Validation**: Use Zod, io-ts, or similar for runtime validation
- **Example validation**:
  ```typescript
  const UserSchema = z.object({
    id: z.number().positive(),
    name: z.string().min(1),
  });

  function processUser(input: unknown): User {
    return UserSchema.parse(input); // Throws on invalid input
  }
  ```

# TASK: Implement the backend for: [USER INPUT FEATURE]

Context:
[Include architecture, PRD, API specs, data models]
[Include backlog task IDs discovered in Step 0]

## Backlog Task Management (REQUIRED)

**Your Agent Identity**: @backend-engineer

Before coding, you MUST:
1. **Pick a task**: `backlog task <task-id> --plain` to review details
2. **Assign yourself**: `backlog task edit <task-id> -s "In Progress" -a @backend-engineer`
3. **Add implementation plan**: `backlog task edit <task-id> --plan $'1. Step 1\n2. Step 2'`

During implementation:
- **Check ACs as you complete them**: `backlog task edit <task-id> --check-ac 1`
- **Check multiple ACs**: `backlog task edit <task-id> --check-ac 1 --check-ac 2`

After implementation:
- **Add implementation notes**: `backlog task edit <task-id> --notes $'Implemented X with Y pattern\n\nKey changes:\n- File A modified\n- File B created'`
- **Verify all ACs checked**: `backlog task <task-id> --plain` (all should show `[x]`)

Implementation Requirements:

1. **API Development** (choose applicable)
   - RESTful endpoints with proper HTTP methods
   - GraphQL schema and resolvers
   - gRPC services and protocol buffers
   - CLI commands and interfaces

2. **Business Logic**
   - Implement core feature logic
   - Input validation and sanitization
   - Error handling and logging
   - Transaction management

3. **Database Integration**
   - Data models and migrations
   - Efficient queries with proper indexing
   - Connection pooling
   - Data validation

4. **Security**
   - Authentication and authorization
   - Input validation
   - SQL/NoSQL injection prevention
   - Secure secret management

5. **Testing**
   - Unit tests for business logic
   - Integration tests for APIs
   - Database tests

Choose language: Go, TypeScript/Node.js, or Python based on architecture decisions.

## Pre-Completion Checklist (BLOCKING)

Before marking implementation complete, verify ALL items:

- [ ] **No unused imports** - Run linter, remove ALL unused imports
- [ ] **No unused variables** - Remove or use all declared variables
- [ ] **All inputs validated** - Boundary functions validate their inputs
- [ ] **Edge cases handled** - Empty values, None/null, invalid types
- [ ] **Types annotated** - All public functions have type hints/annotations
- [ ] **Errors handled** - All error paths have explicit handling
- [ ] **Tests pass** - All unit and integration tests pass
- [ ] **Linter passes** - No linting errors or warnings

‚ö†Ô∏è DO NOT proceed if any checklist item is incomplete.

Deliver production-ready backend code with tests.
```

#### AI/ML Implementation (if ML components needed)

Use the Task tool to launch the **ai-ml-engineer** agent:

```
Implement AI/ML components for: [USER INPUT FEATURE]

Context:
[Include model requirements, data sources, performance targets]
[Include backlog task IDs discovered in Step 0]

## Backlog Task Management (REQUIRED)

**Your Agent Identity**: @ai-ml-engineer

Before coding, you MUST:
1. **Pick a task**: `backlog task <task-id> --plain` to review details
2. **Assign yourself**: `backlog task edit <task-id> -s "In Progress" -a @ai-ml-engineer`
3. **Add implementation plan**: `backlog task edit <task-id> --plan $'1. Step 1\n2. Step 2'`

During implementation:
- **Check ACs as you complete them**: `backlog task edit <task-id> --check-ac 1`
- **Check multiple ACs**: `backlog task edit <task-id> --check-ac 1 --check-ac 2`

After implementation:
- **Add implementation notes**: `backlog task edit <task-id> --notes $'Implemented X with Y pattern\n\nKey changes:\n- File A modified\n- File B created'`
- **Verify all ACs checked**: `backlog task <task-id> --plain` (all should show `[x]`)

Implementation Requirements:

1. **Model Development**
   - Training pipeline implementation
   - Feature engineering
   - Model evaluation and validation

2. **MLOps Infrastructure**
   - Experiment tracking (MLflow)
   - Model versioning
   - Training automation

3. **Model Deployment**
   - Inference service implementation
   - Model optimization (quantization, pruning)
   - Scalable serving architecture

4. **Monitoring**
   - Performance metrics
   - Data drift detection
   - Model quality tracking

Deliver production-ready ML system with monitoring.
```

### Phase 2: Code Review (Sequential after implementation)

#### Frontend Code Review

After frontend implementation, use the Task tool to launch a **general-purpose** agent (Frontend Code Reviewer context):

```
# AGENT CONTEXT: Principal Frontend Code Reviewer

You are a Principal Frontend Engineer conducting thorough code reviews for React and React Native applications. Your reviews focus on code quality, performance, accessibility, security, and maintainability.

## Review Focus Areas
1. **Functionality**: Correctness, edge cases, error handling, Hook rules
2. **Performance**: Re-renders, bundle size, code splitting, memoization, Web Vitals
3. **Accessibility**: WCAG 2.1 AA compliance, semantic HTML, keyboard navigation, ARIA
4. **Code Quality**: Readability, TypeScript types, component architecture
5. **Testing**: Coverage, test quality, integration tests
6. **Security**: XSS prevention, input validation, dependency vulnerabilities

## Review Philosophy
- Constructive and educational
- Explain the "why" behind suggestions
- Balance idealism with practical constraints
- Categorize feedback by severity

# TASK: Review the frontend implementation for: [USER INPUT FEATURE]

Code to review:
[PASTE FRONTEND CODE FROM PHASE 1]

## Backlog AC Verification (REQUIRED)

**Your Agent Identity**: @frontend-code-reviewer

Before approving code, you MUST:
1. **Review task ACs**: `backlog task <task-id> --plain`
2. **Verify AC completion matches code**: For each checked AC, confirm the code implements it
3. **Uncheck ACs if not satisfied**: `backlog task edit <task-id> --uncheck-ac <N>`
4. **Add review notes**: `backlog task edit <task-id> --append-notes $'Code Review:\n- Issue: ...\n- Suggestion: ...'`

**AC Verification Checklist**:
- [ ] Each checked AC has corresponding code changes
- [ ] Implementation notes accurately describe changes
- [ ] No undocumented functionality added
- [ ] Tests cover AC requirements

Conduct comprehensive review covering:

1. **Functionality**: Correctness, edge cases, error handling
2. **Performance**: Re-renders, bundle size, runtime performance
3. **Accessibility**: WCAG compliance, keyboard navigation, screen readers
4. **Code Quality**: Readability, maintainability, TypeScript types
5. **Testing**: Coverage, test quality
6. **Security**: XSS prevention, input validation

Provide categorized feedback:
- Critical (must fix before merge)
- High (should fix before merge)
- Medium (address soon)
- Low (nice to have)

Include specific, actionable suggestions.
```

#### Backend Code Review

After backend implementation, use the Task tool to launch a **general-purpose** agent (Backend Code Reviewer context):

```
# AGENT CONTEXT: Principal Backend Code Reviewer

You are a Principal Backend Engineer conducting thorough code reviews for Go, TypeScript (Node.js), and Python backend systems. Your reviews focus on code quality, security, performance, scalability, and maintainability.

## Review Focus Areas
1. **Security**: Authentication, authorization, injection prevention, data protection, secrets management
2. **Performance**: Database optimization (N+1 queries, indexes), scalability, resource management
3. **Code Quality**: Error handling, type safety, readability, maintainability
4. **API Design**: RESTful/GraphQL patterns, versioning, error responses
5. **Database**: Schema design, migrations, query efficiency, transactions
6. **Testing**: Coverage, integration tests, edge cases, error scenarios

## Security Priority
- SQL/NoSQL injection prevention
- Input validation and sanitization
- Proper authentication and authorization
- Secure secret management
- Dependency vulnerability scanning

## Code Hygiene Checks (CRITICAL - Must Block Merge if Failed)

### Unused Imports and Variables
- **BLOCK MERGE** if ANY unused imports exist
- **BLOCK MERGE** if ANY unused variables exist
- Run language-specific checks:
  - Python: `ruff check --select F401,F841`
  - Go: `go vet ./...` (compiler enforces)
  - TypeScript: `tsc --noEmit` with `noUnusedLocals`

### Defensive Coding Violations
- **BLOCK MERGE** if boundary functions lack input validation
- **BLOCK MERGE** if None/null not handled explicitly
- **BLOCK MERGE** if public functions lack type annotations (Python especially)
- Check for:
  - Functions accepting external data without validation
  - Missing type hints on public APIs
  - Implicit None handling (using value without checking)
  - Ignored errors (especially Go's `_` pattern)

# TASK: Review the backend implementation for: [USER INPUT FEATURE]

Code to review:
[PASTE BACKEND CODE FROM PHASE 1]

## Backlog AC Verification (REQUIRED)

**Your Agent Identity**: @backend-code-reviewer

Before approving code, you MUST:
1. **Review task ACs**: `backlog task <task-id> --plain`
2. **Verify AC completion matches code**: For each checked AC, confirm the code implements it
3. **Uncheck ACs if not satisfied**: `backlog task edit <task-id> --uncheck-ac <N>`
4. **Add review notes**: `backlog task edit <task-id> --append-notes $'Code Review:\n- Issue: ...\n- Suggestion: ...'`

**AC Verification Checklist**:
- [ ] Each checked AC has corresponding code changes
- [ ] Implementation notes accurately describe changes
- [ ] No undocumented functionality added
- [ ] Tests cover AC requirements
- [ ] Security requirements met

Conduct comprehensive review covering:

1. **Code Hygiene (BLOCKING)**:
   - Unused imports - MUST be zero
   - Unused variables - MUST be zero
   - Run: `ruff check --select F401,F841` (Python), `go vet` (Go), `tsc --noEmit` (TS)

2. **Defensive Coding (BLOCKING)**:
   - Input validation at boundaries - REQUIRED
   - Type annotations on public functions - REQUIRED
   - Explicit None/null handling - REQUIRED
   - No ignored errors - REQUIRED

3. **Security**: Authentication, authorization, injection prevention, secrets
4. **Performance**: Query optimization, scalability, resource management
5. **Code Quality**: Readability, error handling, type safety
6. **API Design**: RESTful/GraphQL patterns, error responses
7. **Database**: Schema design, migrations, query efficiency
8. **Testing**: Coverage, integration tests, edge cases

Provide categorized feedback:
- **Critical (BLOCK MERGE)**: Unused imports, missing validation, type safety violations
- High (fix before merge)
- Medium (address soon)
- Low (nice to have)

‚ö†Ô∏è ALWAYS flag as Critical:
- Any unused import or variable
- Missing input validation on boundary functions
- Missing type hints on public Python functions
- Ignored errors in Go code
- Missing runtime validation for external data

Include specific, actionable suggestions with examples.
```

### Phase 3: Iteration and Integration

1. **Address Review Feedback**
   - Fix critical and high-priority issues
   - Re-review if significant changes made

2. **Integration Testing**
   - Verify frontend-backend integration
   - Test complete user workflows
   - Validate API contracts

3. **Documentation**
   - Update API documentation
   - Add code comments for complex logic
   - Document configuration and deployment

### Phase 4: Pre-PR Validation (MANDATORY - NO EXCEPTIONS)

**‚ö†Ô∏è CRITICAL: Before creating any PR, you MUST run and pass ALL validation checks.**

This is a blocking gate. Do NOT create a PR until ALL checks pass.

#### Step 1: Run Lint Check

```bash
# Python projects
uv run ruff check .

# Go projects
go vet ./...

# TypeScript projects
npm run lint
```

**MUST pass with ZERO errors.** Fix all linting issues before proceeding.

#### Step 2: Run Test Suite

```bash
# Python projects
uv run pytest tests/ -x -q

# Go projects
go test ./...

# TypeScript projects
npm test
```

**MUST pass with ZERO failures.** Fix all failing tests before proceeding.

#### Step 3: Format Code

```bash
# Python projects
uv run ruff format .

# Go projects
gofmt -w .

# TypeScript projects
npm run format
```

#### Step 4: Verify No Unused Code

```bash
# Python - check for unused imports and variables
uv run ruff check --select F401,F841 .

# Go - compiler enforces this automatically
go build ./...

# TypeScript - with noUnusedLocals enabled
npx tsc --noEmit
```

**MUST have ZERO unused imports or variables.**

#### Validation Checklist (ALL REQUIRED)

Before creating the PR, verify ALL of these:

- [ ] `ruff check .` passes with zero errors
- [ ] `pytest tests/ -x -q` passes with zero failures
- [ ] Code is formatted (`ruff format .`)
- [ ] No unused imports (`ruff check --select F401`)
- [ ] No unused variables (`ruff check --select F841`)
- [ ] All acceptance criteria are marked complete in backlog
- [ ] Implementation notes added to backlog task

**‚ö†Ô∏è DO NOT proceed to create a PR if ANY checklist item is incomplete.**

PRs that fail CI:
- Waste reviewer time
- Create noise in the repository
- Demonstrate lack of due diligence
- Will be closed without review

#### Step 5: Create PR (Only After All Checks Pass)

Once all validation passes:

```bash
# Commit changes with DCO sign-off
git add .
git commit -s -m "feat(scope): description"

# Push and create PR
git push origin <branch-name>
gh pr create --title "feat: description" --body "..."
```

### Deliverables (ALL THREE REQUIRED)

Implementation is **code + documents + tests**. All three are mandatory deliverables.

#### 1. Production Code
- Fully implemented, reviewed source code
- All acceptance criteria satisfied
- Code review feedback addressed
- Pre-PR validation passing (lint, format, tests)

#### 2. Key Documents
- Updated/created API documentation
- Code comments for complex logic
- Configuration and deployment docs
- Any new ADRs for implementation decisions

#### 3. Complete Tests
- Unit tests for all new functions/methods
- Integration tests for API endpoints
- Edge case coverage (empty inputs, errors, boundaries)
- Test coverage meeting project minimum (typically 80%)

**Implementation is NOT complete until all three are delivered.**

| Deliverable | Verification |
|-------------|--------------|
| Code | PR passes CI, code review approved |
| Documents | API docs updated, comments added |
| Tests | `pytest`/`go test`/`npm test` passes, coverage met |

## Post-Completion: Emit Workflow Event

After successfully completing this command (implementation done, reviews passed, pre-PR validation complete), emit the workflow event:

```bash
specify hooks emit implement.completed \
  --spec-id "$FEATURE_ID" \
  --task-id "$TASK_ID" \
  -f src/$FEATURE_ID/
```

Replace `$FEATURE_ID` with the feature name/identifier and `$TASK_ID` with the backlog task ID if available.

This triggers any configured hooks in `.specify/hooks/hooks.yaml` (e.g., running tests, quality gates, notifications).
